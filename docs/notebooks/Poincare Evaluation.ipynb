{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Poincare Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how well poincare embeddings trained using this [implementation](https://github.com/TatsuyaShirakawa/poincare-embedding) perform on the tasks detailed in the [original paper](https://arxiv.org/pdf/1705.08039.pdf).\n",
    "\n",
    "This is the list of tasks - \n",
    "1. WordNet reconstruction\n",
    "2. WordNet link prediction\n",
    "3. Link prediction in collaboration networks\n",
    "4. Lexical entailment on HyperLex\n",
    "\n",
    "A more detailed explanation of the tasks and the evaluation methodology is present in the individual evaluation subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 C++ embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/gensim\n"
     ]
    }
   ],
   "source": [
    "% cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = '/home/jayant/projects/poincare-embedding/work'  # TODO: put model files into repo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, pdist\n",
    "from smart_open import smart_open\n",
    "\n",
    "def transform_cpp_embedding_to_kv(input_file, output_file, encoding='utf8'):\n",
    "    \"\"\"Given a C++ embedding tsv filepath, converts it to a KeyedVector-supported file\"\"\"\n",
    "    with smart_open(input_file, 'rb') as f:\n",
    "        lines = [line.decode(encoding) for line in f]\n",
    "    if not len(lines):\n",
    "         raise ValueError(\"file is empty\")\n",
    "    first_line = lines[0]\n",
    "    parts = first_line.rstrip().split(\"\\t\")\n",
    "    model_size = len(parts) - 1\n",
    "    vocab_size = len(lines)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('%d %d\\n' % (vocab_size, model_size))\n",
    "        for line in lines:\n",
    "            f.write(line.replace('\\t', ' '))\n",
    "    \n",
    "        \n",
    "class PoincareEmbedding(object):\n",
    "    \"\"\"Load and perform distance operations on poincare embeddings\"\"\"\n",
    "\n",
    "    def __init__(self, keyed_vectors):\n",
    "        \"\"\"Initialize PoincareEmbeddings via a KeyedVectors instance\"\"\"\n",
    "        self.kv = keyed_vectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def poincare_dist(vector_1, vector_2):\n",
    "        \"\"\"Return poincare distance between two vectors\"\"\"\n",
    "        norm_1 = np.linalg.norm(vector_1)\n",
    "        norm_2 = np.linalg.norm(vector_2)\n",
    "        euclidean_dist = euclidean(vector_1, vector_2)\n",
    "        return np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dist ** 2) / ((1 - norm_1 ** 2) * (1 - norm_2 ** 2))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def load_poincare_cpp(cls, input_filename):\n",
    "        \"\"\"Load embeddings trained via C++ Poincare model\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to tsv file containing embeddings\n",
    "\n",
    "        Returns:\n",
    "            PoincareEmbedding instance\n",
    "\n",
    "        \"\"\"\n",
    "        keyed_vectors_filename = input_filename + '.kv'\n",
    "        transform_cpp_embedding_to_kv(input_filename, keyed_vectors_filename)\n",
    "        keyed_vectors = KeyedVectors.load_word2vec_format(keyed_vectors_filename)\n",
    "        os.unlink(keyed_vectors_filename)\n",
    "        return cls(keyed_vectors)\n",
    "    \n",
    "    def get_vector(self, term):\n",
    "        \"\"\"Return vector for given term\"\"\"\n",
    "        return self.kv.word_vec(term)\n",
    "        \n",
    "    def get_all_distances(self, term):\n",
    "        \"\"\"Return distances to all terms for given term, including itself\"\"\"\n",
    "        term_vector = self.kv.word_vec(term)\n",
    "        all_vectors = self.kv.syn0\n",
    "        \n",
    "        euclidean_dists = np.linalg.norm(term_vector - all_vectors, axis=1)\n",
    "        norm = np.linalg.norm(term_vector)\n",
    "        all_norms = np.linalg.norm(all_vectors, axis=1)\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        return np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dists ** 2) / ((1 - norm ** 2) * (1 - all_norms ** 2))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def get_distance(self, term_1, term_2):\n",
    "        \"\"\"Returns distance between vectors for input terms\n",
    "\n",
    "        Args:\n",
    "            term_1 (str)\n",
    "            term_2 (str)\n",
    "\n",
    "        Returns:\n",
    "            Poincare distance between the two terms (float)\n",
    "        \n",
    "        Note:\n",
    "            Raises KeyError if either term_1 or term_2 is absent from vocabulary\n",
    "\n",
    "        \"\"\"\n",
    "        vector_1, vector_2 = self.kv[term_1], self.kv[term_2]\n",
    "        return self.poincare_dist(vector_1, vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "#     'wordnet_embeddings_2.tsv',\n",
    "#     'wordnet_embeddings_5.tsv',\n",
    "#     'wordnet_embeddings_10.tsv',\n",
    "#     'wordnet_embeddings_20.tsv',\n",
    "#     'wordnet_embeddings_20_ep50.tsv',\n",
    "    'wordnet_embeddings_50.tsv',\n",
    "    'wordnet_embeddings_50_ep100.tsv',\n",
    "#     'wordnet_embeddings_100.tsv',\n",
    "]\n",
    "embeddings = {fname: PoincareEmbedding.load_poincare_cpp(os.path.join(embeddings_dir, fname)) for fname in filenames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = embeddings['wordnet_embeddings_50_ep100.tsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = embeddings['wordnet_embeddings_20_ep50.tsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/py3/lib/python3.5/site-packages/ipykernel_launcher.py:72: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/jayant/projects/py3/lib/python3.5/site-packages/ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in arccosh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.5 s, sys: 2.2 s, total: 11.7 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, term in enumerate(test_embedding.kv.vocab.keys(), start=1):\n",
    "    if i > 1000:\n",
    "        break\n",
    "    dists = test_embedding.get_all_distances(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 WordNet reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "\n",
    "class ReconstructionEvaluation(object):\n",
    "    \"\"\"Evaluating reconstruction on given network for any embeddings\"\"\"\n",
    "    def __init__(self, filepath, embedding):\n",
    "        \"\"\"Initialize evaluation instance with tsv file containing relation pairs and embedding to be evaluated\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): path to tsv file containing relation pairs\n",
    "            embedding (PoincareEmbedding instance): embedding to be evaluated\n",
    "        \n",
    "        Returns\n",
    "            ReconstructionEvaluation instance\n",
    "\n",
    "        \"\"\"\n",
    "        items = set()\n",
    "        embedding_vocab = embedding.kv.vocab\n",
    "        positive_relations = defaultdict(set)\n",
    "        with smart_open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                assert len(row) == 2, 'Hypernym pair has more than two items'\n",
    "                item_1_index = embedding_vocab[row[0]].index\n",
    "                item_2_index = embedding_vocab[row[1]].index\n",
    "                positive_relations[item_1_index].add(item_2_index)\n",
    "                items.update([item_1_index, item_2_index])\n",
    "        self.items = items\n",
    "        self.positive_relations = positive_relations\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_positive_item_ranks(distances, positive_item_indices):\n",
    "        \"\"\"Given a numpy array of distances and indices of positive items, compute ranks of positive item distances\n",
    "        \n",
    "        Args:\n",
    "            distances (numpy float array): np array of all distances for a specific item\n",
    "            positive_item_indices (list): list of indices of positive items\n",
    "        \n",
    "        Returns:\n",
    "            list of ranks of positive items in the same order as `positive_indices`\n",
    "        \"\"\"\n",
    "        positive_item_distances = distances[positive_item_indices]\n",
    "        if np.any(positive_item_distances == np.inf):\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        negative_item_distances = np.ma.array(distances, mask=False)\n",
    "        negative_item_distances.mask[positive_item_indices] = True\n",
    "        # Compute how many negative item distances are less than each positive item distance, plus 1 for rank\n",
    "        ranks = (negative_item_distances < positive_item_distances[:, np.newaxis]).sum(axis=1) + 1\n",
    "        return list(ranks) \n",
    "\n",
    "    def evaluate_reconstruction(self, max_n=None):\n",
    "        \"\"\"Evaluate mean rank and MAP for reconstruction\n",
    "            \n",
    "        Args:\n",
    "            max_n (int or None): Maximum number of positive relations to evaluate, all if max_n is None\n",
    "        \n",
    "        Returns:\n",
    "            ??\n",
    "\n",
    "        \"\"\"\n",
    "        ranks = []\n",
    "        for i, item in enumerate(self.items, start=1):\n",
    "            if not i % 1000:\n",
    "                print('Evaluating item number %d: %s' % (i, item))\n",
    "            if item not in self.positive_relations:\n",
    "                continue\n",
    "            positive_items = list(self.positive_relations[item])\n",
    "            item_term = self.embedding.kv.index2word[item]\n",
    "            item_distances = self.embedding.get_all_distances(item_term)\n",
    "            positive_item_ranks = self.get_positive_item_ranks(item_distances, positive_items)\n",
    "            ranks += positive_item_ranks\n",
    "            if max_n is not None and i > max_n:\n",
    "                break\n",
    "        return np.mean(ranks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_instance = ReconstructionEvaluation(os.path.join(embeddings_dir, 'wordnet_noun_hypernyms.tsv'), test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating item 0 0\n",
      "Evaluating item 1000 1000\n",
      "72.8014208014\n",
      "CPU times: user 11.6 s, sys: 2.08 s, total: 13.7 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(np.mean(eval_instance.evaluate_reconstruction(test_embedding)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 WordNet link prediction\n",
    "TODO (tricky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 HyperLex lexical entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "class LexicalEntailmentEvaluation(object):\n",
    "    \"\"\"Evaluating reconstruction on given network for any embeddings\"\"\"\n",
    "    def __init__(self, filepath, embedding):\n",
    "        \"\"\"Initialize evaluation instance with HyperLex text file containing relation pairs\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): path to HyperLex text file\n",
    "            embedding (PoincareEmbedding instance): embedding to be evaluated\n",
    "        \n",
    "        Returns\n",
    "            LexicalEntailmentEvaluation instance\n",
    "\n",
    "        \"\"\"\n",
    "        expected_scores = {}\n",
    "        with smart_open(filepath, 'r') as f:\n",
    "            reader = csv.DictReader(f, delimiter=' ')\n",
    "            for row in reader:\n",
    "                word_1, word_2 = row['WORD1'], row['WORD2']\n",
    "                expected_scores[(word_1, word_2)] = float(row['AVG_SCORE'])\n",
    "        self.scores = expected_scores\n",
    "        self.embedding = embedding\n",
    "        self.alpha = 1000\n",
    "    \n",
    "    def score_function(self, term_1, term_2):\n",
    "        \"\"\"Given two terms, return the predicted score for them (extent to which term_1 is a type of term_2)\"\"\"\n",
    "        distance = self.embedding.get_distance(term_1, term_2)\n",
    "        vector_1, vector_2 = self.embedding.get_vector(term_1), self.embedding.get_vector(term_2)\n",
    "        norm_1, norm_2 = np.linalg.norm(vector_1), np.linalg.norm(vector_2)\n",
    "        return -(1 + self.alpha(norm_2 - norm_1)) * distance\n",
    "        \n",
    "    def evaluate_spearman(self, embeddings):\n",
    "        \"\"\"Evaluate spearman scores for lexical entailment for given embeddings\n",
    "            \n",
    "        Args:\n",
    "            embeddings (PoincareEmbedding instance): embeddings for which evaluation is to be done\n",
    "        \n",
    "        Returns:\n",
    "            ??\n",
    "\n",
    "        \"\"\"\n",
    "        predicted_scores = []\n",
    "        expected_scores = []\n",
    "        for (term_1, term_2), expected_score in self.scores.items():\n",
    "            predicted_scores.append(self.score_function(term_1, term_2))\n",
    "            expected_scores.append(expected_score)\n",
    "        spearman = spearmanr(expected_scores, predicted_scores).correlation\n",
    "        import pdb\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_instance = LexicalEntailmentEvaluation(os.path.join(embeddings_dir, 'nouns-verbs', 'hyperlex-nouns.txt'), test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'asia' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-3fc22e9815b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_spearman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-228-4692553b6dd8>\u001b[0m in \u001b[0;36mevaluate_spearman\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mexpected_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mpredicted_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mexpected_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mspearman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-228-4692553b6dd8>\u001b[0m in \u001b[0;36mscore_function\u001b[0;34m(self, term_1, term_2)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;34m\"\"\"Given two terms, return the predicted score for them (extent to which term_1 is a type of term_2)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mvector_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mnorm_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-4d96d1cdecb0>\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(self, term_1, term_2)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mvector_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoincare_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gensim/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gensim/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'asia' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "eval_instance.evaluate_spearman(test_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Link Prediction for collaboration networks\n",
    "TODO (tricky)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
