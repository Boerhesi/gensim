{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Poincare Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how well poincare embeddings trained using this [implementation](https://github.com/TatsuyaShirakawa/poincare-embedding) perform on the tasks detailed in the [original paper](https://arxiv.org/pdf/1705.08039.pdf).\n",
    "\n",
    "This is the list of tasks - \n",
    "1. WordNet reconstruction\n",
    "2. WordNet link prediction\n",
    "3. Link prediction in collaboration networks\n",
    "4. Lexical entailment on HyperLex\n",
    "\n",
    "A more detailed explanation of the tasks and the evaluation methodology is present in the individual evaluation subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 C++ embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/gensim\n"
     ]
    }
   ],
   "source": [
    "% cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = '/home/jayant/projects/poincare-embedding/work'  # TODO: put model files into repo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, pdist\n",
    "from smart_open import smart_open\n",
    "\n",
    "def transform_cpp_embedding_to_kv(input_file, output_file, encoding='utf8'):\n",
    "    \"\"\"Given a C++ embedding tsv filepath, converts it to a KeyedVector-supported file\"\"\"\n",
    "    with smart_open(input_file, 'rb') as f:\n",
    "        lines = [line.decode(encoding) for line in f]\n",
    "    if not len(lines):\n",
    "         raise ValueError(\"file is empty\")\n",
    "    first_line = lines[0]\n",
    "    parts = first_line.rstrip().split(\"\\t\")\n",
    "    model_size = len(parts) - 1\n",
    "    vocab_size = len(lines)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('%d %d\\n' % (vocab_size, model_size))\n",
    "        for line in lines:\n",
    "            f.write(line.replace('\\t', ' '))\n",
    "    \n",
    "        \n",
    "class PoincareEmbedding(object):\n",
    "    \"\"\"Load and perform distance operations on poincare embeddings\"\"\"\n",
    "\n",
    "    def __init__(self, keyed_vectors):\n",
    "        \"\"\"Initialize PoincareEmbeddings via a KeyedVectors instance\"\"\"\n",
    "        self.kv = keyed_vectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def poincare_dist(vector_1, vector_2):\n",
    "        \"\"\"Return poincare distance between two vectors\"\"\"\n",
    "        norm_1 = np.linalg.norm(vector_1)\n",
    "        norm_2 = np.linalg.norm(vector_2)\n",
    "        euclidean_dist = euclidean(vector_1, vector_2)\n",
    "        return np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dist ** 2) / ((1 - norm_1 ** 2) * (1 - norm_2 ** 2))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def load_poincare_cpp(cls, input_filename):\n",
    "        \"\"\"Load embeddings trained via C++ Poincare model\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to tsv file containing embeddings\n",
    "\n",
    "        Returns:\n",
    "            PoincareEmbedding instance\n",
    "\n",
    "        \"\"\"\n",
    "        keyed_vectors_filename = input_filename + '.kv'\n",
    "        transform_cpp_embedding_to_kv(input_filename, keyed_vectors_filename)\n",
    "        keyed_vectors = KeyedVectors.load_word2vec_format(keyed_vectors_filename)\n",
    "        os.unlink(keyed_vectors_filename)\n",
    "        return cls(keyed_vectors)\n",
    "    \n",
    "    def get_all_distances(self, term):\n",
    "        \"\"\"Return distances to all terms for given term, including itself\"\"\"\n",
    "        term_vector = self.kv.word_vec(term)\n",
    "        all_vectors = self.kv.syn0\n",
    "        \n",
    "        euclidean_dists = np.linalg.norm(term_vector - all_vectors, axis=1)\n",
    "        norm = np.linalg.norm(term_vector)\n",
    "        all_norms = np.linalg.norm(all_vectors, axis=1)\n",
    "\n",
    "        return np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dists ** 2) / ((1 - norm ** 2) * (1 - all_norms ** 2))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def get_distance(self, term_1, term_2):\n",
    "        \"\"\"Returns distance between vectors for input terms\n",
    "\n",
    "        Args:\n",
    "            term_1 (str)\n",
    "            term_2 (str)\n",
    "\n",
    "        Returns:\n",
    "            Poincare distance between the two terms (float)\n",
    "        \n",
    "        Note:\n",
    "            Raises KeyError if either term_1 or term_2 is absent from vocabulary\n",
    "\n",
    "        \"\"\"\n",
    "        vector_1, vector_2 = self.kv[term_1], self.kv[term_2]\n",
    "        return self.poincare_dist(vector_1, vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "#     'wordnet_embeddings_2.tsv',\n",
    "#     'wordnet_embeddings_5.tsv',\n",
    "    'wordnet_embeddings_10.tsv',\n",
    "#     'wordnet_embeddings_20.tsv',\n",
    "#     'wordnet_embeddings_50.tsv',\n",
    "#     'wordnet_embeddings_100.tsv',\n",
    "]\n",
    "embeddings = {fname: PoincareEmbedding.load_poincare_cpp(os.path.join(embeddings_dir, fname)) for fname in filenames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = embeddings['wordnet_embeddings_10.tsv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/py3/lib/python3.5/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/jayant/projects/py3/lib/python3.5/site-packages/ipykernel_launcher.py:71: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.6 s, sys: 0 ns, total: 39.6 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, term in enumerate(test_embedding.kv.vocab.keys(), start=1):\n",
    "    if i > 10000:\n",
    "        break\n",
    "    dists = test_embedding.get_all_distances(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 WordNet reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "\n",
    "class ReconstructionEvaluation(object):\n",
    "    \"\"\"Evaluating reconstruction on given network for any embeddings\"\"\"\n",
    "    def __init__(self, filepath, embedding):\n",
    "        \"\"\"Initialize evaluation instance with tsv file containing relation pairs\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): path to tsv file containing relation pairs\n",
    "        \n",
    "        Returns\n",
    "            ReconstructionEvaluation instance\n",
    "\n",
    "        \"\"\"\n",
    "        items = set()\n",
    "        embedding_vocab = embedding.kv.vocab\n",
    "        positive_relations = defaultdict(set)\n",
    "        with smart_open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                assert len(row) == 2, 'Hypernym pair has more than two items'\n",
    "                item_1_index = embedding_vocab[row[0]].index\n",
    "                item_2_index = embedding_vocab[row[1]].index\n",
    "                positive_relations[item_1_index].add(item_2_index)\n",
    "                items.update([item_1_index, item_2_index])\n",
    "        self.items = items\n",
    "        self.positive_relations = positive_relations\n",
    "        self.embedding = embedding\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_positive_item_ranks(distances, positive_item_indices):\n",
    "        \"\"\"Given a numpy array of distances and indices of positive items, compute ranks of positive item distances\n",
    "        \n",
    "        Args:\n",
    "            distances (numpy float array): np array of all distances for a specific item\n",
    "            positive_item_indices (list): list of indices of positive items\n",
    "        \n",
    "        Returns:\n",
    "            list of ranks of positive items in the same order as `positive_indices`\n",
    "        \"\"\"\n",
    "        positive_item_distances = distances[positive_item_indices]\n",
    "        negative_item_distances = np.ma.array(distances, mask=False)\n",
    "        negative_item_distances.mask[positive_item_indices] = True\n",
    "        # Compute how many negative item distances are less than each positive item distance, plus 1 for rank\n",
    "        ranks = (negative_item_distances < positive_item_distances[:, np.newaxis]).sum(axis=1) + 1\n",
    "        return list(ranks) \n",
    "\n",
    "    def evaluate_reconstruction(self, embeddings):\n",
    "        \"\"\"Evaluate mean rank and MAP for reconstruction for given embeddings\n",
    "            \n",
    "        Args:\n",
    "            embeddings (PoincareEmbedding instance): embeddings for which evaluation is to be done\n",
    "        \n",
    "        Returns:\n",
    "            ??\n",
    "\n",
    "        \"\"\"\n",
    "        ranks = []\n",
    "        for i, item in enumerate(self.items):\n",
    "            if not i % 1000:\n",
    "                print('Evaluating item %d %s' % (i, item))\n",
    "            if item not in self.positive_relations:\n",
    "                continue\n",
    "            positive_items = list(self.positive_relations[item])\n",
    "            item_term = self.embedding.kv.index2word[item]\n",
    "            item_distances = self.embedding.get_all_distances(item_term)\n",
    "            positive_item_ranks = self.get_positive_item_ranks(item_distances, positive_items)\n",
    "            ranks += positive_item_ranks\n",
    "            if i > 20000:\n",
    "                break\n",
    "        return np.mean(ranks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_instance = ReconstructionEvaluation(os.path.join(embeddings_dir, 'wordnet_noun_hypernyms.tsv'), test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating item 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/py3/lib/python3.5/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating item 1000 1000\n",
      "Evaluating item 2000 2000\n",
      "Evaluating item 3000 3000\n",
      "Evaluating item 4000 4000\n",
      "Evaluating item 5000 5000\n",
      "Evaluating item 6000 6000\n",
      "Evaluating item 7000 7000\n",
      "Evaluating item 8000 8000\n",
      "Evaluating item 9000 9000\n",
      "Evaluating item 10000 10000\n",
      "Evaluating item 11000 11000\n",
      "Evaluating item 12000 12000\n",
      "Evaluating item 13000 13000\n",
      "Evaluating item 14000 14000\n",
      "Evaluating item 15000 15000\n",
      "Evaluating item 16000 16000\n",
      "Evaluating item 17000 17000\n",
      "Evaluating item 18000 18000\n",
      "Evaluating item 19000 19000\n",
      "Evaluating item 20000 20000\n",
      "116.01562108\n",
      "CPU times: user 1min 55s, sys: 4 ms, total: 1min 55s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(np.mean(eval_instance.evaluate_reconstruction(test_embedding)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 WordNet link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 HyperLex lexical entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Link Prediction for collaboration networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
