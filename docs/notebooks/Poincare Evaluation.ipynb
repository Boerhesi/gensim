{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Poincare Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how well poincare embeddings trained using this [implementation](https://github.com/TatsuyaShirakawa/poincare-embedding) perform on the tasks detailed in the [original paper](https://arxiv.org/pdf/1705.08039.pdf).\n",
    "\n",
    "This is the list of tasks - \n",
    "1. WordNet reconstruction\n",
    "2. WordNet link prediction\n",
    "3. Link prediction in collaboration networks\n",
    "4. Lexical entailment on HyperLex\n",
    "\n",
    "A more detailed explanation of the tasks and the evaluation methodology is present in the individual evaluation subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 C++ embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/gensim\n"
     ]
    }
   ],
   "source": [
    "% cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = '/home/jayant/projects/poincare-embedding/work'  # TODO: put model files into repo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, pdist\n",
    "from smart_open import smart_open\n",
    "\n",
    "def transform_cpp_embedding_to_kv(input_file, output_file, encoding='utf8'):\n",
    "    \"\"\"Given a C++ embedding tsv filepath, converts it to a KeyedVector-supported file\"\"\"\n",
    "    with smart_open(input_file, 'rb') as f:\n",
    "        lines = [line.decode(encoding) for line in f]\n",
    "    if not len(lines):\n",
    "         raise ValueError(\"file is empty\")\n",
    "    first_line = lines[0]\n",
    "    parts = first_line.rstrip().split(\"\\t\")\n",
    "    model_size = len(parts) - 1\n",
    "    vocab_size = len(lines)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('%d %d\\n' % (vocab_size, model_size))\n",
    "        for line in lines:\n",
    "            f.write(line.replace('\\t', ' '))\n",
    "    \n",
    "        \n",
    "class PoincareEmbedding(object):\n",
    "    \"\"\"Load and perform distance operations on poincare embeddings\"\"\"\n",
    "\n",
    "    def __init__(self, keyed_vectors):\n",
    "        \"\"\"Initialize PoincareEmbeddings via a KeyedVectors instance\"\"\"\n",
    "        self.kv = keyed_vectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def poincare_dist(vector_1, vector_2):\n",
    "        \"\"\"Return poincare distance between two vectors\"\"\"\n",
    "        norm_1 = np.linalg.norm(vector_1)\n",
    "        norm_2 = np.linalg.norm(vector_2)\n",
    "        euclidean_dist = euclidean(vector_1, vector_2)\n",
    "        return np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dist ** 2) / ((1 - norm_1 ** 2) * (1 - norm_2 ** 2))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def load_poincare_cpp(cls, input_filename):\n",
    "        \"\"\"Load embeddings trained via C++ Poincare model\n",
    "\n",
    "        Args:\n",
    "            filepath (str): Path to tsv file containing embeddings\n",
    "\n",
    "        Returns:\n",
    "            PoincareEmbedding instance\n",
    "\n",
    "        \"\"\"\n",
    "        keyed_vectors_filename = input_filename + '.kv'\n",
    "        transform_cpp_embedding_to_kv(input_filename, keyed_vectors_filename)\n",
    "        keyed_vectors = KeyedVectors.load_word2vec_format(keyed_vectors_filename)\n",
    "        os.unlink(keyed_vectors_filename)\n",
    "        return cls(keyed_vectors)\n",
    "       \n",
    "    def get_distances(self, term_1, terms):\n",
    "        \"\"\"Returns distance between vector for term and vectors for given terms\n",
    "        Args:\n",
    "            term_1 (str)\n",
    "            terms (list/tuple/set): terms for which distance from vector for term_1 is to be returned\n",
    "\n",
    "        Returns:\n",
    "            List of Poincare distances between term_1 and all terms in `terms` (list of floats)\n",
    "\n",
    "        \"\"\"\n",
    "        term_1_vector = self.kv.word_vec(term_1)\n",
    "\n",
    "        vocab = self.kv.vocab\n",
    "        terms_indices = [vocab[term].index for term in terms]\n",
    "        other_vectors = self.kv.syn0[terms_indices]\n",
    "        \n",
    "        euclidean_dists = np.linalg.norm(term_1_vector - other_vectors, axis=1)\n",
    "        norm_1 = np.linalg.norm(term_1_vector)\n",
    "        other_norms = np.linalg.norm(other_vectors, axis=1)\n",
    "\n",
    "        return list(np.arccosh(\n",
    "            1 + 2 * (\n",
    "                (euclidean_dists ** 2) / ((1 - norm_1 ** 2) * (1 - other_norms ** 2))\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        \n",
    "    def get_distance(self, term_1, term_2):\n",
    "        \"\"\"Returns distance between vectors for input terms\n",
    "\n",
    "        Args:\n",
    "            term_1 (str)\n",
    "            term_2 (str)\n",
    "\n",
    "        Returns:\n",
    "            Poincare distance between the two terms (float)\n",
    "        \n",
    "        Note:\n",
    "            Raises KeyError if either term_1 or term_2 is absent from vocabulary\n",
    "\n",
    "        \"\"\"\n",
    "        vector_1, vector_2 = self.kv[term_1], self.kv[term_2]\n",
    "        return self.poincare_dist(vector_1, vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "#     'wordnet_embeddings_2.tsv',\n",
    "#     'wordnet_embeddings_5.tsv',\n",
    "    'wordnet_embeddings_10.tsv',\n",
    "#     'wordnet_embeddings_20.tsv',\n",
    "#     'wordnet_embeddings_50.tsv',\n",
    "#     'wordnet_embeddings_100.tsv',\n",
    "]\n",
    "embeddings = {fname: PoincareEmbedding.load_poincare_cpp(os.path.join(embeddings_dir, fname)) for fname in filenames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 WordNet reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "def get_rank(sorted_list, given_value):\n",
    "    \"\"\"Return rank of given value in sorted list (sorted in increasing order)\"\"\"\n",
    "    for i, value in enumerate(sorted_list, start=1):\n",
    "        if given_value < value:\n",
    "            return i\n",
    "    return len(sorted_list) + 1\n",
    "\n",
    "class ReconstructionEvaluation(object):\n",
    "    \"\"\"Evaluating reconstruction on given network for any embeddings\"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"Initialize evaluation instance with tsv file containing relation pairs\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): path to tsv file containing relation pairs\n",
    "        \n",
    "        Returns\n",
    "            ReconstructionEvaluation instance\n",
    "\n",
    "        \"\"\"\n",
    "        items = set()\n",
    "        relation_pairs = defaultdict(set)\n",
    "        with smart_open(filepath, 'r') as f:\n",
    "            reader = csv.reader(f, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                assert len(row) == 2, 'Hypernym pair has more than two items'\n",
    "                relation_pairs[row[0]].add(row[1])\n",
    "                items.update(row)\n",
    "        self.items = items\n",
    "        self.relation_pairs = relation_pairs\n",
    "    \n",
    "    def get_negative_instances(self, item, max_n=None):\n",
    "        \"\"\"Get all item that don't have a relation with given item\n",
    "        \n",
    "        Args:\n",
    "            item (str): item for which negative instances are to be returned\n",
    "            max_n (int or None): Return at most max_n negative instances. Return all if None\n",
    "        \n",
    "        Returns:\n",
    "            set of items which don't have a relation with input item\n",
    "\n",
    "        \"\"\"\n",
    "        related_items = self.relation_pairs[item]\n",
    "        negative_items = {item_ for item_ in self.items if item_ not in related_items}\n",
    "        if max_n is not None:\n",
    "            return set(itertools.islice(negative_items, max_n))\n",
    "        else:\n",
    "            return negative_items\n",
    "\n",
    "    def evaluate_reconstruction(self, embeddings):\n",
    "        \"\"\"Evaluate mean rank and MAP for reconstruction for given embeddings\n",
    "            \n",
    "        Args:\n",
    "            embeddings (PoincareEmbedding instance): embeddings for which evaluation is to be done\n",
    "        \n",
    "        Returns:\n",
    "            ??\n",
    "\n",
    "        \"\"\"\n",
    "        ranks = []\n",
    "        for i, item in enumerate(self.items):\n",
    "            if not i % 1000:\n",
    "                print('Evaluating item %d %s' % (i, item))\n",
    "            if item not in self.relation_pairs:\n",
    "                continue\n",
    "            positive_items = self.relation_pairs[item]\n",
    "            negative_items = self.get_negative_instances(item)\n",
    "            negative_item_distances = embeddings.get_distances(item, negative_items)\n",
    "            negative_item_distances = sorted(negative_item_distances)\n",
    "            positive_item_distances = embeddings.get_distances(item, positive_items)\n",
    "            positive_item_ranks = [get_rank(negative_item_distances, positive_item_distance) for positive_item_distance in positive_item_distances]\n",
    "            ranks += positive_item_ranks\n",
    "            if i > 100:\n",
    "                break\n",
    "        return ranks\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_instance = ReconstructionEvaluation(os.path.join(embeddings_dir, 'wordnet_noun_hypernyms.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating item 0 pica.n.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/py3/lib/python3.5/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "%lprun -f PoincareEmbedding.get_distances eval_instance.evaluate_reconstruction(test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating item 0 pica.n.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayant/projects/py3/lib/python3.5/site-packages/ipykernel_launcher.py:82: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.080472103\n",
      "CPU times: user 12.6 s, sys: 0 ns, total: 12.6 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(np.mean(eval_instance.evaluate_reconstruction(test_embedding)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 WordNet link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 HyperLex lexical entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Link Prediction for collaboration networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
